{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification\n",
    "\n",
    "This notebook demonstrates how `homonim` can help improve classifier accuracy.  It works with images and ground truth taken from a [vegetation mapping study](https://doi.org/10.1117/1.jrs.12.046022) that sought to identify Spekboom in the Little Karoo, South Africa.  Aerial imagery with 50 cm spatial resolution and 4 spectral bands (red, green, blue and near-infrared) was obtained from the  [NGI](https://ngi.dalrrd.gov.za/index.php/what-we-do/aerial-photography-and-imagery).  Ground truth data consists of ± 160 polygons with labels for 3 classes: \n",
    "\n",
    "- Spekboom: a species of succulent shrub.\n",
    "- Tree: any other tree. \n",
    "- Background: other vegetation, bare ground etc.\n",
    "\n",
    "## Setup\n",
    "\n",
    "### Install dependencies\n",
    "\n",
    "`geedim`, `geopandas`, `gdal`, `matplotlib`, `sklearn` and `scipy` are required to run the notebook.  You can uncomment the cell below to install them, if they aren't installed already."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import sys\n",
    "# if 'conda' in sys.prefix:\n",
    "#     # install into the conda environment the notebook is being run from\n",
    "#     !conda install --yes --prefix {sys.prefix} -c conda-forge geedim geopandas gdal matplotlib sklearn scipy\n",
    "# else:\n",
    "#     # install into the python environment the notebook is being run from\n",
    "#     !{sys.executable} -m pip install geedim geopandas gdal matplotlib sklearn scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports used by more than one cell\n",
    "import logging\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "from matplotlib import pyplot\n",
    "import numpy as np\n",
    "import rasterio as rio\n",
    "import pandas as pd\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "import geedim as gd\n",
    "\n",
    "logging.basicConfig(level=logging.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initialise source and reference paths\n",
    "from glob import glob\n",
    "src_root = Path(\n",
    "    'V:/Data/HomonimEgs/NGI_3321BD-3322AC_2010_LittleKaroo/Source/'\n",
    "    'GroundTruthSubset'\n",
    ")\n",
    "src_mosaic_path = src_root.joinpath(\n",
    "    'NGI_3321BD-3322AC_2010_LittleKaroo_GroundTruthSubset_Source.vrt'\n",
    ")\n",
    "src_paths = [\n",
    "    Path(src_path) \n",
    "    for src_path in glob(str(src_root.joinpath('*_RGBN_CMP.tif')))\n",
    "]\n",
    "\n",
    "ref_root = Path(\n",
    "    'V:/Data/HomonimEgs/NGI_3321BD-3322AC_2010_LittleKaroo/Reference/'\n",
    "    'GroundTruthSubset'\n",
    ")\n",
    "l7_ref_path = ref_root.joinpath('l7_comp_ref.tif')\n",
    "modis_ref_path = ref_root.joinpath('modis_nbar_ref.tif')\n",
    "\n",
    "# create a search region that covers the source image mosaic\n",
    "region = gd.utils.get_bounds(src_mosaic_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Search and download reference images\n",
    "\n",
    "Use [`geedim`](https://github.com/dugalh/geedim) to search for and download Landsat-7 and MODIS NBAR reference images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image property descriptions:\n",
      "\n",
      "ABBREV     NAME                  DESCRIPTION\n",
      "---------  --------------------  ---------------------------------------\n",
      "ID         system:id             Earth Engine image id\n",
      "DATE       system:time_start     Image capture date/time (UTC)\n",
      "FILL       FILL_PORTION          Portion of valid pixels (%)\n",
      "CLOUDLESS  CLOUDLESS_PORTION     Portion of cloud/shadow free pixels (%)\n",
      "GRMSE      GEOMETRIC_RMSE_MODEL  Orthorectification RMSE (m)\n",
      "SAA        SUN_AZIMUTH           Solar azimuth angle (deg)\n",
      "SEA        SUN_ELEVATION         Solar elevation angle (deg)\n",
      "\n",
      "Search Results:\n",
      "\n",
      "ID                                          DATE              FILL CLOUDLESS GRMSE   SAA   SEA\n",
      "------------------------------------------- ---------------- ----- --------- ----- ----- -----\n",
      "LANDSAT/LE07/C02/T1_L2/LE07_173083_20100203 2010-02-03 08:14 92.12     92.10  4.74 73.32 52.10\n",
      "LANDSAT/LE07/C02/T1_L2/LE07_173083_20100219 2010-02-19 08:14 92.01     92.01  4.58 66.61 49.04\n"
     ]
    }
   ],
   "source": [
    "# Note: soure images captured from 2010-01-22 - 2010-02-01\n",
    "gd.Initialize()\n",
    "\n",
    "# create and search the Landsat-7 collection\n",
    "l7_coll = gd.MaskedCollection.from_name('LANDSAT/LE07/C02/T1_L2')\n",
    "l7_coll = l7_coll.search(\n",
    "    '2010-01-01', '2010-02-28', region, cloudless_portion=50\n",
    ")\n",
    "print('Image property descriptions:\\n\\n' + l7_coll.schema_table)\n",
    "print('\\nSearch Results:\\n\\n' + l7_coll.properties_table)\n",
    "\n",
    "# equivalent geedim command line:\n",
    "# !geedim search -c l7-c2-l2 -s 2010-01-01 -e 2010-02-28 -cp 50  -r {src_mosaic_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "daf0b546338f4145acfbcf2733623c41",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "l7_comp_ref.tif: |                                                     | 0.00/367M (raw) [  0.0%] in 00:00 (et…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# create a composite of L7 search results to fill in SLE gaps\n",
    "l7_comp_im = l7_coll.composite(\n",
    "    gd.CompositeMethod.q_mosaic, date='2010-01-27', \n",
    "    resampling=gd.ResamplingMethod.bilinear,\n",
    ")\n",
    "\n",
    "# get source mosaic CRS for download parameter\n",
    "with rio.open(src_mosaic_path, 'r') as ds:\n",
    "    src_crs = ds.crs.to_wkt()\n",
    "\n",
    "# download\n",
    "l7_comp_im.download(\n",
    "    l7_ref_path, crs=src_crs, scale=30, region=region, \n",
    "    scale_offset=True, overwrite=True\n",
    ")\n",
    "\n",
    "# equivalent geedim command line:\n",
    "# !geedim composite  -cm q_mosaic --date 2010-01-27 -i LANDSAT/LE07/C02/T1_L2/LE07_173083_20100203 -i LANDSAT/LE07/C02/T1_L2/LE07_173083_20100219 download --crs {src_crs}  --scale 30 -r {src_mosaic_path}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image property descriptions:\n",
      "\n",
      "ABBREV  NAME               DESCRIPTION\n",
      "------  -----------------  -----------------------------\n",
      "ID      system:id          Earth Engine image id\n",
      "DATE    system:time_start  Image capture date/time (UTC)\n",
      "FILL    FILL_PORTION       Portion of valid pixels (%)\n",
      "\n",
      "Search Results:\n",
      "\n",
      "ID                           DATE             FILL\n",
      "---------------------------- ---------------- ----\n",
      "MODIS/006/MCD43A4/2022_01_27 2022-01-27 00:00  100\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1fc3cd1dd8004e78a492c486bd60082e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "modis_nbar_ref.tif: |                                                  | 0.00/278k (raw) [  0.0%] in 00:00 (et…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# search the MODIS NBAR collection\n",
    "modis_coll = gd.MaskedCollection.from_name('MODIS/006/MCD43A4')\n",
    "modis_coll = modis_coll.search(\n",
    "    '2022-01-27', '2022-01-28', region, \n",
    ")\n",
    "print('Image property descriptions:\\n\\n' + modis_coll.schema_table)\n",
    "print('\\nSearch Results:\\n\\n' + modis_coll.properties_table)\n",
    "\n",
    "# download\n",
    "modis_image = gd.MaskedImage.from_id(\n",
    "    'MODIS/006/MCD43A4/2010_01_27', mask=True\n",
    ")\n",
    "modis_image.download(\n",
    "    modis_ref_path, region=region, dtype='uint16', scale_offset=True, \n",
    "    overwrite=True\n",
    ")\n",
    "\n",
    "# equivalent geedim command line:\n",
    "# !geedim search -c modis-nbar -s 2010-01-27 -e 2010-01-28 -r {src_mosaic_path} download -o"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Correction\n",
    "\n",
    "Setup correction parameters and paths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homonim import Model, ProcCrs, utils\n",
    "if False:\n",
    "    # fuse with Landsat-7 and compare with MODIS NBAR\n",
    "    ref_bands = [3, 2, 1, 4]\n",
    "    cmp_ref_bands = [1, 4, 3, 2]\n",
    "    ref_path = l7_ref_path\n",
    "    cmp_ref_path = modis_ref_path\n",
    "    model = Model.gain\n",
    "    kernel_shape = (5, 5)\n",
    "    corr_root = Path(\n",
    "        'V:/Data/HomonimEgs/NGI_3321BD-3322AC_2010_LittleKaroo/Corrected/'\n",
    "        'GroundTruthSubset/L7/'\n",
    "    )\n",
    "    ref_sc_off = [.2, 0]\n",
    "    out_profile = None\n",
    "else:\n",
    "    # fuse with MODIS NBAR and compare with Landsat-7\n",
    "    ref_bands = [1, 4, 3, 2]\n",
    "    cmp_ref_bands = [3, 2, 1, 4]\n",
    "    ref_path = modis_ref_path\n",
    "    cmp_ref_path = l7_ref_path\n",
    "    model = Model.gain\n",
    "    kernel_shape = (1, 1)\n",
    "    corr_root = Path(\n",
    "        'V:/Data/HomonimEgs/NGI_3321BD-3322AC_2010_LittleKaroo/Corrected/'\n",
    "        'GroundTruthSubset/Modis/'\n",
    "    )\n",
    "    ref_sc_off = [1.7e3, .1]\n",
    "    out_profile = None\n",
    "\n",
    "post_fix = utils.create_out_postfix(\n",
    "    ProcCrs.ref, model=model, kernel_shape=kernel_shape, driver='GTiff'\n",
    ")\n",
    "corr_paths = [\n",
    "    corr_root.joinpath(src_path.stem + post_fix)\n",
    "    for src_path in src_paths\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fuse aerial images with reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3321b_3172_12_0415_rgbn_CMP_FUSE_cREF_mGAIN_k1_1.tif:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "adc45a80ac77441f9fbcf9b5849c5ad1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                             |0/4 blocks …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3321b_3172_12_0419_rgbn_CMP_FUSE_cREF_mGAIN_k1_1.tif:\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8ed7c7dccfcd4a98bac97066822fa44f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|                                                                                             |0/4 blocks …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from homonim import RasterFuse\n",
    "\n",
    "for src_path, corr_path in zip(src_paths, corr_paths):\n",
    "    with RasterFuse(src_path, ref_path, ref_bands=ref_bands) as raster_fuse:\n",
    "        print(f'{corr_path.name}:')\n",
    "        raster_fuse.process(\n",
    "            corr_path, model, kernel_shape, \n",
    "            block_config=dict(threads=4, max_block_mem=512), \n",
    "            out_profile=out_profile, \n",
    "            model_config=dict(mask_partial=False), \n",
    "            overwrite=True\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Create a VRT mosaic of the corrected images to use in the visualisation and evaluation steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from osgeo import gdal\n",
    "\n",
    "# strictly, one should avoid using GDAL and rasterio together, but it doesn't\n",
    "# create conflicts here\n",
    "corr_mosaic_path = corr_root.joinpath(\n",
    "    f'NGI_3321BD-3322AC_2010_LittleKaroo_GroundTruthSubset{post_fix[:-4]}.vrt'\n",
    ")\n",
    "ds = gdal.BuildVRT(\n",
    "    str(corr_mosaic_path.absolute()), [str(cp) for cp in corr_paths]\n",
    ")\n",
    "ds.FlushCache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualise\n",
    "\n",
    "Display matching extents of the source, reference and corrected images, in the reference CRS."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio.vrt import WarpedVRT\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio.plot import show\n",
    "\n",
    "# get source crs\n",
    "with rio.open(src_mosaic_path, 'r') as ds:\n",
    "    src_crs = ds.crs\n",
    "\n",
    "fig, axes = pyplot.subplots(\n",
    "    3, 1, sharex=True, sharey=True, tight_layout=True, figsize=(10, 15), \n",
    "    dpi=100\n",
    ")\n",
    "\n",
    "# loop over src, ref and corrected images and corrsonding parameters\n",
    "for im_file, ds_fact, indexes, sc_off, ax, label in zip(\n",
    "    [src_mosaic_path, ref_path, corr_mosaic_path],\n",
    "    [16, 1, 16],                           # downsample factor\n",
    "    [None, ref_bands, None],               # band indices\n",
    "    [None, ref_sc_off, ref_sc_off],        # colour scale & offset\n",
    "    axes,\n",
    "    ['Source', 'Reference', 'Corrected'], \n",
    "):\n",
    "    # read image\n",
    "    with (rio.open(im_file, 'r')) as ds:\n",
    "        if ds.crs != src_crs:\n",
    "            # re-project to source CRS\n",
    "            ds = WarpedVRT(ds, crs=src_crs, resampling=Resampling.bilinear)\n",
    "        with ds:\n",
    "            # read and downsample image\n",
    "            ds_shape = tuple(np.round(np.array(ds.shape) / ds_fact).astype('int'))\n",
    "            transform = ds.transform * rio.Affine.scale(ds_fact)\n",
    "\n",
    "            array = ds.read(indexes=indexes, out_dtype='float32', out_shape=ds_shape)\n",
    "\n",
    "    # change nodata value to nan\n",
    "    mask = np.any((array == ds.nodata) | np.isnan(array), axis=(0))\n",
    "    array[:, mask] = np.nan\n",
    "\n",
    "    # contrast stretching for display\n",
    "    if sc_off is not None:\n",
    "        # scale and offset pixel values\n",
    "        array = np.clip((array / sc_off[0]) - sc_off[1], 0, 1)\n",
    "    else:\n",
    "        # 'normalise' image 2%-98% -> 0-1\n",
    "        for bi in range(array.shape[0]):\n",
    "            array[bi] -= np.nanpercentile(array[bi], 1)\n",
    "            array[bi] /= np.nanpercentile(array[bi], 99)\n",
    "            array[bi] = np.clip(array[bi], 0, 1)\n",
    "\n",
    "    # display\n",
    "    ax = show(array[0:3], transform=transform, interpolation='nearest', ax=ax)\n",
    "    ax.set_title(label, fontweight='bold')\n",
    "    ax.axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Comparison\n",
    "\n",
    "Compare corrected images with a second surface reflectance reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from homonim import RasterCompare\n",
    "\n",
    "print(RasterCompare.schema_table())\n",
    "\n",
    "# loop over the source and corrected image files\n",
    "for im_path, im_label in zip(\n",
    "    [src_mosaic_path, corr_mosaic_path],\n",
    "    ['Source', 'Corrected'],\n",
    "):\n",
    "    with RasterCompare(\n",
    "        im_path, cmp_ref_path, ref_bands=cmp_ref_bands,\n",
    "    ) as compare:\n",
    "        # print a table of comparison statistics (the typical way of using \n",
    "        # RasterCompare)\n",
    "        print(f'{im_label}:')\n",
    "        stats_dict = compare.process()\n",
    "        print(f'{im_label} comparison:\\n\\n' + compare.stats_table(stats_dict))\n",
    "\n",
    "    # equivalent homonim command line:\n",
    "    # !homonim compare {im_path} {cmp_ref_path}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classification\n",
    "\n",
    "Compare classification performance before and after correction with `homonim`.  \n",
    "\n",
    "### Feature extraction\n",
    "\n",
    "Start by reading ground truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "groundtruth_path = ref_root.joinpath('LittleKaroo3ClassGroundTruth.gpkg')\n",
    "class_label_gdf = gpd.GeoDataFrame.from_file(groundtruth_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then extract band pixel values (features) for ground truth polygons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rasterio import features\n",
    "from rasterio import windows\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "def extract_feats(\n",
    "    ds: rio.DatasetReader, labelled_plot_gdf: gpd.GeoDataFrame\n",
    ") -> pd.DataFrame:\n",
    "    \"\"\" Extract pixel features from image for given plots. \"\"\"\n",
    "    px_feats_dict = dict(plot_id=[], label=[])\n",
    "\n",
    "    # loop over ground truth plots\n",
    "    for plot_id, plot in tqdm(\n",
    "        labelled_plot_gdf.to_crs(ds.crs).iterrows(), \n",
    "        total=labelled_plot_gdf.shape[0], desc=im_path.name, \n",
    "        dynamic_ncols=True,\n",
    "    ):\n",
    "        if plot.Class is None:\n",
    "            continue\n",
    "\n",
    "        # find a rasterio window that contains the plot polygon\n",
    "        bounds = features.bounds(plot.geometry)\n",
    "        win = windows.from_bounds(*bounds, transform=ds.transform)\n",
    "        win = utils.expand_window_to_grid(win)\n",
    "\n",
    "        # read the image array corresponding to the plot window\n",
    "        array = ds.read(out_dtype='float64', window=win)\n",
    "\n",
    "        # find a mask for pixels contained inside the plot polygon\n",
    "        win_transform = ds.window_transform(win)\n",
    "        with warnings.catch_warnings():\n",
    "            warnings.simplefilter('ignore')     # ignore shapely deprecation warning            \n",
    "            mask = ~features.geometry_mask(\n",
    "                plot.geometry, (win.height, win.width), transform=win_transform\n",
    "            )\n",
    "\n",
    "        def app_listval(d: dict, k: str, val: list):\n",
    "            \"\"\" Append a list to a dictionary value. \"\"\"\n",
    "            if k in d:\n",
    "                d[k] += val\n",
    "            else:\n",
    "                d[k] = val\n",
    "            return d\n",
    "\n",
    "        # extract band values for pixels inside polygon\n",
    "        for bi, fname in zip([0, 1, 2, 3], ['R', 'G', 'B', 'NIR']):\n",
    "            feat = array[bi]\n",
    "            featv = list(feat[mask])\n",
    "            px_feats_dict = app_listval(px_feats_dict, fname, featv)\n",
    "\n",
    "        # copy plot id and class label for these pixels\n",
    "        px_feats_dict['plot_id'] += [plot_id] * len(featv)\n",
    "        px_feats_dict['label'] += [plot.Class] * len(featv)\n",
    "    \n",
    "    df = pd.DataFrame(px_feats_dict)\n",
    "    # pca = PCA(n_components=2)\n",
    "    # pca.fit(df[['R', 'G', 'B', 'NIR']])\n",
    "    # pc = pca.transform(df[['R', 'G', 'B', 'NIR']])\n",
    "    # df['pc1'] = pc[:, 0]\n",
    "    # df['pc2'] = pc[:, 1]\n",
    "    return df\n",
    "\n",
    "# extract features from source and corrected image mosaics\n",
    "feats = []\n",
    "for im_path in [src_mosaic_path, corr_mosaic_path]:    \n",
    "    with rio.open(im_path, 'r') as ds:\n",
    "        feats_gdf = extract_feats(ds, class_label_gdf)\n",
    "    feats_gdf['label_i'] = pd.Categorical(feats_gdf['label']).codes\n",
    "    feats.append(feats_gdf)\n",
    "feats_dict = dict(zip(['Source', 'Corrected'], feats))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature visualisation\n",
    "\n",
    "Visualise scatter of source and corrected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: KDE class plot\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "def class_scatter(\n",
    "    df: pd.DataFrame, x=None, y=None, z=None, label_col='label', ax=None\n",
    "):\n",
    "    \"\"\" Feature scatter plot, with class colour coding. \"\"\"\n",
    "    colours = dict(zip(\n",
    "        pd.Categorical(feats_gdf[label_col]).categories, \n",
    "        ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'o']\n",
    "    ))\n",
    "    for label, group in df.groupby(label_col):\n",
    "        if z is None:\n",
    "            ax = group.plot.scatter(\n",
    "                x, y, s=1, label=label, ax=ax, c=colours[label], alpha=0.1,\n",
    "            )\n",
    "        else:\n",
    "            ax.scatter(\n",
    "                group[x], group[y], group[z], s=1, label=label, \n",
    "                c=colours[label], alpha=0.1, \n",
    "            )\n",
    "    ax.legend()\n",
    "    for lh in ax.legend().legendHandles: \n",
    "        lh.set_alpha(1)\n",
    "\n",
    "fig, axes = pyplot.subplots(\n",
    "    1, 2, tight_layout=True, figsize=(12, 5), dpi=100, #subplot_kw=dict(projection='3d')\n",
    ")\n",
    "\n",
    "for feats_df, ax, label in zip(\n",
    "    feats_dict.values(), axes, feats_dict.keys(),\n",
    "):\n",
    "    class_scatter(feats_df.iloc[::10], 'NIR', 'B', ax=ax)\n",
    "    ax.set_title(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy import stats\n",
    "from matplotlib import cm\n",
    "\n",
    "def class_kde(\n",
    "    df: pd.DataFrame, x=None, y=None, label_col='label', ax=None\n",
    "):\n",
    "    \"\"\" Feature scatter plot, with class colour coding. \"\"\"\n",
    "    colours = dict(zip(\n",
    "        pd.Categorical(feats_gdf[label_col]).categories, \n",
    "        ['r', 'g', 'b', 'c', 'm', 'y', 'k', 'o']\n",
    "    ))\n",
    "    def get_ptile_range(v, n=100):\n",
    "        return np.linspace(\n",
    "            np.percentile(v, .25), np.percentile(v, 98), n\n",
    "        )\n",
    "    xrange = get_ptile_range(df[x])\n",
    "    yrange = get_ptile_range(df[y])\n",
    "    xx, yy = np.meshgrid(xrange, yrange)  \n",
    "    pos = np.vstack([xx.ravel(), yy.ravel()])\n",
    "    kdes = []\n",
    "    for label, group in df.groupby(label_col):\n",
    "        val = np.vstack([group[x], group[y]])\n",
    "        kernel = stats.gaussian_kde(val)\n",
    "        kde = np.reshape(kernel(pos).T, xx.shape)\n",
    "        kde /= kde.max()\n",
    "        kdes.append(kde)\n",
    "        # cset = ax.contour(\n",
    "        #     xx, yy, kde, colors=colours[label], alpha=0.4, \n",
    "        # )\n",
    "        ax.plot(xx[0], yy[0], f'{colours[label]}o', ms=10, alpha=0, label=label)\n",
    "    \n",
    "    im = np.dstack(kdes)\n",
    "    ax.imshow(\n",
    "        im, extent=[xrange[0], xrange[-1], yrange[0], yrange[-1]], \n",
    "        interpolation='bilinear', origin='lower'\n",
    "    )\n",
    "    ax.axis('auto')\n",
    "    ax.set_xlabel(x)\n",
    "    ax.set_ylabel(y)\n",
    "    ax.legend(loc='upper left')\n",
    "    for lh in ax.legend(loc='upper left').legendHandles: \n",
    "        lh.set_alpha(.2)\n",
    "\n",
    "fig, axes = pyplot.subplots(\n",
    "    1, 2, tight_layout=True, figsize=(12, 5), dpi=100, \n",
    ")\n",
    "\n",
    "for feats_df, ax, label in zip(\n",
    "    feats_dict.values(), axes, feats_dict.keys(),\n",
    "):\n",
    "    class_kde(feats_df.iloc[::10], 'NIR', 'B', ax=ax)\n",
    "    ax.set_title(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification accuracy\n",
    "\n",
    "Evaluate the accuracy of a naive Bayes classifier on the source and corrected features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import StratifiedKFold, StratifiedGroupKFold\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from tabulate import tabulate\n",
    "\n",
    "def train_test(\n",
    "    X: np.ndarray, y: np.ndarray, groups: np.ndarray = None, n_splits=10,\n",
    "    clf = GaussianNB()\n",
    ") -> np.ndarray:\n",
    "    \"\"\" \n",
    "    Train and test a classifier on the given features and labels using \n",
    "    cross-validation. \n",
    "    \"\"\"\n",
    "    if groups is not None:\n",
    "        tr_ts_indices = StratifiedGroupKFold(n_splits=n_splits).split(\n",
    "            X, y, groups\n",
    "        )\n",
    "    else:\n",
    "        tr_ts_indices = StratifiedKFold(n_splits=n_splits).split(X, y)\n",
    "    \n",
    "    ypred = np.zeros_like(y)\n",
    "    for train, test in tqdm(\n",
    "        tr_ts_indices, dynamic_ncols=True, total=n_splits\n",
    "    ):\n",
    "        Xtr = X[train, :]\n",
    "        ytr = y[train]\n",
    "        Xts = X[test, :]\n",
    "        yts = y[test]\n",
    "        # clf = DecisionTreeClassifier(class_weight='balanced')\n",
    "        clf.fit(Xtr, ytr)\n",
    "        ypred[test] = clf.predict(Xts)\n",
    "    return ypred\n",
    "\n",
    "label_col = 'label'\n",
    "for df_label, df in feats_dict.items():\n",
    "    \n",
    "    # raw spectral band feature matrix\n",
    "    X = df[['R', 'G', 'B', 'NIR']].to_numpy()\n",
    "    # X = df[['pc1', 'pc2']].to_numpy()\n",
    "    # convert string class labels to int codes\n",
    "    y = pd.Categorical(df[label_col]).codes  \n",
    "    \n",
    "    class_labels = pd.Categorical(df[label_col]).categories\n",
    "    \n",
    "    priors = np.ones(len(class_labels)) / len(class_labels)\n",
    "    scaler = StandardScaler()\n",
    "    pca = PCA(n_components=1)\n",
    "    clf = GaussianNB(priors=priors)\n",
    "    pipe = Pipeline(steps=[(\"scaler\", scaler), (\"pca\", pca), (\"clf\", clf)])\n",
    "    \n",
    "    ypred = train_test(\n",
    "        X, y, groups=df.plot_id.to_numpy(), clf=pipe, n_splits=10\n",
    "    )\n",
    "    cm = confusion_matrix(y, ypred)\n",
    "    cm_norm = cm / cm.sum(axis=1).reshape(-1, 1)\n",
    "    cm_df = pd.DataFrame(data=cm, columns=class_labels, index=class_labels)\n",
    "    cm_norm_df = pd.DataFrame(\n",
    "        data=cm_norm, columns=class_labels, index=class_labels\n",
    "    )\n",
    "\n",
    "    print(f'{df_label}:')\n",
    "    # print(classification_report(y, ypred, target_names=class_labels))\n",
    "    print(f'Confusion matrix:')\n",
    "    print(tabulate(cm_df, headers=cm_df.columns, tablefmt='rst', floatfmt='.2f'))\n",
    "    print(f'\\nNormalised confusion matrix:')\n",
    "    print(tabulate(cm_norm_df, headers=cm_norm_df.columns, tablefmt='rst', floatfmt='.2f'))\n",
    "    print(f'\\nAccuracy: {100*np.sum(np.diag(cm))/np.sum(cm[:]):.2f}')\n",
    "    print(f'Norm accuracy: {100*np.mean(np.diag(cm_norm)):.2f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "a5cb0e16c618ce62d5962a2f34302e2d299d083ff8e8afee2c1c64a34662e4b4"
   }
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "07b89bb9911d46328ad0a50cdce90467": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "0c316212fa594a1f8071a7d43f905873": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "105ec8c20c394e94ac889674ea60ea41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "1ec34dc1fdc0489a8e2d61acc321837a": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_7709f04445c946409029fd9e857d8733",
       "max": 367222080,
       "style": "IPY_MODEL_251a17937a8647b0aedc16772fc17331",
       "value": 367222080
      }
     },
     "1fc3cd1dd8004e78a492c486bd60082e": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_26aac1e22af84510a81aff6a31cc89a0",
        "IPY_MODEL_8f37e071edb940f6be421521237f3647",
        "IPY_MODEL_a51472aee55546c892fac0fd05d4e44c"
       ],
       "layout": "IPY_MODEL_e477cac3af7f4d578acf032914dcd2d3"
      }
     },
     "223c583359c247a5a7ccbaf6e1d2a03f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "251a17937a8647b0aedc16772fc17331": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "26aac1e22af84510a81aff6a31cc89a0": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_537527124e3945a08a9739d3d8531d33",
       "style": "IPY_MODEL_8fe910d95b8144e6bcf8734f302c27c7",
       "value": "modis_nbar_ref.tif: "
      }
     },
     "2c7b03dd25b549d4805bc8b78bbde203": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "2e29978a074545aa99fb2539919084ad": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "36f48f98d4d44c85bad066d79744d1f3": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_9ceef4321a0e42d9ade6829e57a3ee7e",
       "style": "IPY_MODEL_5ea5cecd311347bfbc2e76a60ec2f6f5",
       "value": "0/4 blocks [00:00&lt;?]"
      }
     },
     "416f331d057c45d786e343e10ee943a5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "43be1a3c47224c628ce96c8a4e4cac64": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_223c583359c247a5a7ccbaf6e1d2a03f",
       "style": "IPY_MODEL_c2b3557e8bce4088abe8ac292bc07593",
       "value": "100%"
      }
     },
     "47986cd670564942bbf46c546d1fc1bf": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "537527124e3945a08a9739d3d8531d33": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "571d564f7141470c8b7d3cde06787909": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_cdfee11477f44a82ab44883220ab635a",
       "max": 4,
       "style": "IPY_MODEL_47986cd670564942bbf46c546d1fc1bf",
       "value": 4
      }
     },
     "5ea5cecd311347bfbc2e76a60ec2f6f5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "5fe1fd693ca64f35b5eb4ca5e7e46004": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_99019babd0ab419b8f0556d72e84da05",
       "style": "IPY_MODEL_105ec8c20c394e94ac889674ea60ea41",
       "value": "l7_comp_ref.tif: "
      }
     },
     "718af11a210648a4967ee69b3e92a728": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "7709f04445c946409029fd9e857d8733": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "8647ef86a3314878a012fcf3703a9ec5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "883aed3e1d484d6c827214b992463b78": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_b7aafb77cdb54dd78d8847c49b7ee841",
       "style": "IPY_MODEL_8647ef86a3314878a012fcf3703a9ec5",
       "value": " 367M/367M (raw) [100.0%] in 00:30 (eta: 00:00)"
      }
     },
     "8ed7c7dccfcd4a98bac97066822fa44f": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_e5ac30f1b0ab4aada0f02089df7b56dd",
        "IPY_MODEL_9d0b3a5700754f86bf7964fad807ea79",
        "IPY_MODEL_36f48f98d4d44c85bad066d79744d1f3"
       ],
       "layout": "IPY_MODEL_2c7b03dd25b549d4805bc8b78bbde203"
      }
     },
     "8f37e071edb940f6be421521237f3647": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_07b89bb9911d46328ad0a50cdce90467",
       "max": 278160,
       "style": "IPY_MODEL_718af11a210648a4967ee69b3e92a728",
       "value": 278160
      }
     },
     "8fe910d95b8144e6bcf8734f302c27c7": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "942b411848414f74a02da46145fce5f4": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "95f9304ef7544e9ba1bf6c6c2fcda7d5": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "96a7ae0c426348d681b801996db27053": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "99019babd0ab419b8f0556d72e84da05": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9ceef4321a0e42d9ade6829e57a3ee7e": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "9d0b3a5700754f86bf7964fad807ea79": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "FloatProgressModel",
      "state": {
       "layout": "IPY_MODEL_2e29978a074545aa99fb2539919084ad",
       "max": 4,
       "style": "IPY_MODEL_a55e76384d46479e99b426258b6acc2b"
      }
     },
     "a0b6ec8507bc43d88028ab9648db98e8": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_f7dd05cf218c4ec7b79fd6b0b61ed8cd",
       "style": "IPY_MODEL_0c316212fa594a1f8071a7d43f905873",
       "value": "4/4 blocks [01:08&lt;00:00]"
      }
     },
     "a4ee0805cac0413383cadebc64769d58": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "a51472aee55546c892fac0fd05d4e44c": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_942b411848414f74a02da46145fce5f4",
       "style": "IPY_MODEL_416f331d057c45d786e343e10ee943a5",
       "value": " 278k/278k (raw) [100.0%] in 00:03 (eta: 00:00)"
      }
     },
     "a55e76384d46479e99b426258b6acc2b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "adc45a80ac77441f9fbcf9b5849c5ad1": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_43be1a3c47224c628ce96c8a4e4cac64",
        "IPY_MODEL_571d564f7141470c8b7d3cde06787909",
        "IPY_MODEL_a0b6ec8507bc43d88028ab9648db98e8"
       ],
       "layout": "IPY_MODEL_95f9304ef7544e9ba1bf6c6c2fcda7d5"
      }
     },
     "b7aafb77cdb54dd78d8847c49b7ee841": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "c2b3557e8bce4088abe8ac292bc07593": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "cdfee11477f44a82ab44883220ab635a": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "flex": "2"
      }
     },
     "daf0b546338f4145acfbcf2733623c41": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_5fe1fd693ca64f35b5eb4ca5e7e46004",
        "IPY_MODEL_1ec34dc1fdc0489a8e2d61acc321837a",
        "IPY_MODEL_883aed3e1d484d6c827214b992463b78"
       ],
       "layout": "IPY_MODEL_ea157fd778e344f58f0bbb01fe3d5a67"
      }
     },
     "e477cac3af7f4d578acf032914dcd2d3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "e5ac30f1b0ab4aada0f02089df7b56dd": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_a4ee0805cac0413383cadebc64769d58",
       "style": "IPY_MODEL_96a7ae0c426348d681b801996db27053",
       "value": "  0%"
      }
     },
     "ea157fd778e344f58f0bbb01fe3d5a67": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "display": "inline-flex",
       "flex_flow": "row wrap",
       "width": "100%"
      }
     },
     "f7dd05cf218c4ec7b79fd6b0b61ed8cd": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
